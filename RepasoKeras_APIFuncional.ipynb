{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RepasoKeras_APIFuncional.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Patriciafg27/MIA3_MachineLearning/blob/main/RepasoKeras_APIFuncional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ1tIWQ3soHE"
      },
      "source": [
        "# Keras\n",
        "\n",
        "Keras es una librería construída para el prototipado rápido de modelos de deep learning. Las ventajas de Keras frente a otros frameworks de deep learning son obvios:\n",
        "\n",
        "- Rápido prototipado (entrenamiento y evaluación) de modelos de deep learning.\n",
        "\n",
        "- Posee una api sencilla con la que se pueden añadir estructuras complejas en redes de neuronas (capas).\n",
        "\n",
        "- Se integra con las herramientas de tensorflow de forma nativa.\n",
        "\n",
        "Keras permite construir modelos utilizando diferentes tipos de api (Application Porgram Interface). Las distintas apis tienen sus ventajas e inconvenientes, en esta clase vamos a estudiar la api secuencial y la api funcional de Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE6_0KlCzQBg"
      },
      "source": [
        "# Keras Sequential API\n",
        "\n",
        "La api secuencial de Keras permite construir modelos añadiendo capas en forma de secuencia. Su uso es muy directo siguiendo los siguientes pasos:\n",
        "\n",
        "- Definimos el modelo utilizando la clase Sequential.\n",
        "\n",
        "- Añadimos capas al modelo utilizando el método .add()\n",
        "\n",
        "- Comppilamos el modelo utilizando el método .compile()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqkkRezH2Y-Y"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrkI4arDzPVX"
      },
      "source": [
        "# Ejemplo\n",
        "dataset = sns.load_dataset(\"iris\") #Cargamos datos\n",
        "model = keras.models.Sequential() #Definimos modelo secuencial. Le ponemos capa densa y un softmax\n",
        "layer_1 = keras.layers.Dense(10, activation=\"relu\")\n",
        "output = keras.layers.Dense(3, activation=\"softmax\") #Como tiene 3 clases le ponemos un 3.\n",
        "model.add(layer_1)\n",
        "model.add(output)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "627ZVXM-OpLC",
        "outputId": "97dff697-ed16-4591-e24e-dccbb75f3650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(layer_1) #Sabe que es una capa"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.layers.core.dense.Dense"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYD7ok2vO0k6",
        "outputId": "b835444b-7ba8-40ec-a37f-c548ab69fa3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(output)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.layers.core.dense.Dense"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDIx86HmOjFk",
        "outputId": "1650d7c1-d2ce-43e7-d52a-c5bdc3c4883d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(model) #Keras distingue entre funcional y secuencial"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.engine.sequential.Sequential"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sPqmTkl3Ld8"
      },
      "source": [
        "X = dataset.iloc[:,:-1]\n",
        "Y = dataset.iloc[:,-1:]\n",
        "Y_dummies = pd.get_dummies(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y_dummies)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBH3c6I65X8_",
        "outputId": "3462222b-3995-429e-c768-39583cc294cd"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=300)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 3ms/step - loss: 3.9726\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 3.7371\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 3.5024\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 3.2806\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.0541\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.8405\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.6287\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4299\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.2522\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.0797\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.9287\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.7904\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.6721\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5704\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4924\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.4157\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3660\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3173\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2734\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2437\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2211\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2033\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1904\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1777\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1674\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1582\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1488\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1391\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1295\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1205\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1119\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1032\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0945\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0862\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0778\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0684\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0597\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0511\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0424\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0338\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0257\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0174\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0088\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0009\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9930\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9851\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9782\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9700\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9623\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9552\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9475\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9402\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9332\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9263\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9187\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9116\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9047\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8978\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8910\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8843\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8775\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8710\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8642\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8575\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8513\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8450\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8388\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8329\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8264\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8212\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8146\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8092\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8032\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7975\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7917\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7856\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7804\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7745\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7691\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7637\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7586\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7534\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7482\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7434\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7382\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7329\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7282\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7231\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7184\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7138\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7091\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7044\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7003\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6953\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6911\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6866\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6823\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6789\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6739\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6696\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6656\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6614\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6578\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6539\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6500\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6465\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6427\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6388\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6349\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6311\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6273\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6230\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6194\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6153\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6115\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6075\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6035\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5994\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5956\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5920\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5878\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5837\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5802\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5760\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5719\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5679\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5639\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5602\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5567\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5535\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5492\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5451\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5414\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5378\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5344\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5309\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5274\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5244\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5212\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5183\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5152\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5129\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5103\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5072\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5048\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5022\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4996\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4973\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4950\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4929\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4902\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4879\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4856\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4833\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4811\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4793\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4769\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4747\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4726\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4705\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4684\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4664\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4643\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4624\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4603\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4583\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4563\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4545\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4530\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4507\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4489\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4469\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4452\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4432\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4415\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4403\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4382\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4361\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4346\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4329\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4311\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4293\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4276\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4263\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4245\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4230\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4213\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4198\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4181\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4164\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4149\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4134\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4118\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4104\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4091\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4075\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4060\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4044\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4031\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4016\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4002\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3987\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3973\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3957\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3945\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3934\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3919\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3906\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3891\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3876\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3864\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3851\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3840\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3826\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3816\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3798\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3785\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3774\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3765\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3747\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3734\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3723\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3710\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3697\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3688\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3673\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3663\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3649\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3638\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3626\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3613\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3601\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3591\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3578\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3566\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3555\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3544\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3533\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3523\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3513\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3503\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3494\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3482\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3473\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3456\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3447\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3438\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3426\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3415\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3406\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3391\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3379\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3370\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3364\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3356\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3347\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3332\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3321\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3309\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3299\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3288\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3283\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3271\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3260\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3249\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3240\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3229\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3220\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3212\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3200\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3194\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3180\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3171\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3161\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3151\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3141\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3132\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3122\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3116\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3102\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3094\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3092\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3083\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3071\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3061\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3052\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3039\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3030\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3023\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3024\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3009\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2996\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2986\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2978\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2970\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2963\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2953\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2942\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2933\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2926\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3f1f393d90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65HyLVmZ53Mg",
        "outputId": "ff7155bb-263e-4a1b-8a58-387a1ba472cd"
      },
      "source": [
        "# Realizar predicción\n",
        "model.predict(X_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.5148122e-02, 4.3128967e-01, 5.5356222e-01],\n",
              "       [6.4481571e-02, 6.5853173e-01, 2.7698672e-01],\n",
              "       [1.3840471e-02, 3.7241292e-01, 6.1374652e-01],\n",
              "       [6.8295537e-03, 2.1193126e-01, 7.8123927e-01],\n",
              "       [9.7218418e-01, 2.7257349e-02, 5.5854645e-04],\n",
              "       [9.0623504e-01, 8.9331329e-02, 4.4335783e-03],\n",
              "       [1.5526500e-02, 4.1800556e-01, 5.6646794e-01],\n",
              "       [9.3699104e-01, 6.0254499e-02, 2.7544436e-03],\n",
              "       [9.1274589e-02, 6.9032604e-01, 2.1839938e-01],\n",
              "       [6.7290917e-02, 7.2556150e-01, 2.0714763e-01],\n",
              "       [2.4711128e-02, 6.3344526e-01, 3.4184366e-01],\n",
              "       [4.6200389e-03, 2.0596032e-01, 7.8941959e-01],\n",
              "       [5.6923173e-02, 7.2374356e-01, 2.1933329e-01],\n",
              "       [3.4754982e-03, 1.8510313e-01, 8.1142139e-01],\n",
              "       [1.0298195e-02, 3.5871243e-01, 6.3098931e-01],\n",
              "       [3.1016653e-03, 1.8208718e-01, 8.1481117e-01],\n",
              "       [9.8206812e-01, 1.7577955e-02, 3.5392112e-04],\n",
              "       [7.1256082e-03, 3.5082883e-01, 6.4204556e-01],\n",
              "       [5.5134457e-02, 7.3623621e-01, 2.0862925e-01],\n",
              "       [2.8685700e-02, 6.9283670e-01, 2.7847755e-01],\n",
              "       [9.2997164e-01, 6.7164972e-02, 2.8634774e-03],\n",
              "       [3.1659741e-02, 6.9807273e-01, 2.7026755e-01],\n",
              "       [9.4995058e-01, 4.8488751e-02, 1.5607472e-03],\n",
              "       [4.7934605e-03, 3.0925697e-01, 6.8594956e-01],\n",
              "       [9.2570764e-01, 7.0958629e-02, 3.3337201e-03],\n",
              "       [1.8483821e-02, 5.4928929e-01, 4.3222687e-01],\n",
              "       [4.7531324e-03, 2.7129748e-01, 7.2394931e-01],\n",
              "       [9.6051669e-01, 3.8411222e-02, 1.0720320e-03],\n",
              "       [7.3953401e-03, 3.0980173e-01, 6.8280298e-01],\n",
              "       [9.1966265e-01, 7.7009216e-02, 3.3281618e-03],\n",
              "       [9.4867784e-01, 4.9729042e-02, 1.5931005e-03],\n",
              "       [9.1197044e-01, 8.3976127e-02, 4.0534222e-03],\n",
              "       [9.5931631e-01, 3.9450739e-02, 1.2329352e-03],\n",
              "       [9.6381545e-01, 3.5107277e-02, 1.0772434e-03],\n",
              "       [3.2074142e-02, 7.2600925e-01, 2.4191654e-01],\n",
              "       [1.8324288e-02, 4.9560064e-01, 4.8607504e-01],\n",
              "       [2.4641285e-02, 5.8046538e-01, 3.9489341e-01],\n",
              "       [9.6403372e-01, 3.5028484e-02, 9.3781442e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_WHdeAGP83y",
        "outputId": "51e94066-b125-40c4-f4f4-849220e5cc5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.layers #Ver las capas"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.dense.Dense at 0x7f3f2320d3d0>,\n",
              " <keras.layers.core.dense.Dense at 0x7f3f231fec50>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjo2sQNXP_IX",
        "outputId": "93ad7163-1297-4b53-b855-b87c7dcf6778",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.layers[0] #Acceder a ellas"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f3f2320d3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaQgchbtQDV3",
        "outputId": "ede267e9-df85-4d98-cc8c-3183fc954d25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.layers[0].weights[0] #Sacar los pesos"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'dense_6/kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
              "array([[-0.05907703,  0.13594085,  0.58555615,  0.03290524,  0.06702138,\n",
              "        -0.15852037, -0.20654792, -0.2584232 , -0.34970734,  0.6617251 ],\n",
              "       [-0.51540715,  0.5908997 ,  0.4861669 ,  0.49165756, -0.07305044,\n",
              "         0.0795387 , -0.4412767 , -0.33541903,  0.45225474,  0.5537486 ],\n",
              "       [ 0.42653835, -0.36291283, -0.1412799 ,  0.12522598,  0.47711432,\n",
              "        -0.43787223, -0.1277976 ,  0.08147305,  0.7352755 , -0.26756904],\n",
              "       [-0.4920831 , -0.80346584, -0.9752599 ,  0.3465238 ,  0.29343835,\n",
              "        -0.05373859, -0.26805922,  0.5977533 ,  0.0754126 , -0.52686226]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORMA--U0QHvB",
        "outputId": "c6329faf-9c03-4e94-aa59-029242e29a5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.layers[0].weights[0].numpy() #Cada fila representa a que columna cada peso."
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.05907703,  0.13594085,  0.58555615,  0.03290524,  0.06702138,\n",
              "        -0.15852037, -0.20654792, -0.2584232 , -0.34970734,  0.6617251 ],\n",
              "       [-0.51540715,  0.5908997 ,  0.4861669 ,  0.49165756, -0.07305044,\n",
              "         0.0795387 , -0.4412767 , -0.33541903,  0.45225474,  0.5537486 ],\n",
              "       [ 0.42653835, -0.36291283, -0.1412799 ,  0.12522598,  0.47711432,\n",
              "        -0.43787223, -0.1277976 ,  0.08147305,  0.7352755 , -0.26756904],\n",
              "       [-0.4920831 , -0.80346584, -0.9752599 ,  0.3465238 ,  0.29343835,\n",
              "        -0.05373859, -0.26805922,  0.5977533 ,  0.0754126 , -0.52686226]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgWaSJmEQdFL"
      },
      "source": [
        "model.pop() #Elimina la ultima capa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iDZAFdO7oWQ"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Entrenad un modelo de 3 capas densas utilizando la api secuencial de Keras para el dataset penguins. El objetivo es clasificar el sexo del pingüino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxurCQonRGgz",
        "outputId": "ca6f7497-ea21-4c7c-d155-c11a6b3b5958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "dataset = sns.load_dataset(\"penguins\")\n",
        "dataset.dropna(inplace=True)\n",
        "dataset.head(10)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>190.0</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>38.9</td>\n",
              "      <td>17.8</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3625.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.2</td>\n",
              "      <td>19.6</td>\n",
              "      <td>195.0</td>\n",
              "      <td>4675.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>41.1</td>\n",
              "      <td>17.6</td>\n",
              "      <td>182.0</td>\n",
              "      <td>3200.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>38.6</td>\n",
              "      <td>21.2</td>\n",
              "      <td>191.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>34.6</td>\n",
              "      <td>21.1</td>\n",
              "      <td>198.0</td>\n",
              "      <td>4400.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   species     island  bill_length_mm  ...  flipper_length_mm  body_mass_g     sex\n",
              "0   Adelie  Torgersen            39.1  ...              181.0       3750.0    Male\n",
              "1   Adelie  Torgersen            39.5  ...              186.0       3800.0  Female\n",
              "2   Adelie  Torgersen            40.3  ...              195.0       3250.0  Female\n",
              "4   Adelie  Torgersen            36.7  ...              193.0       3450.0  Female\n",
              "5   Adelie  Torgersen            39.3  ...              190.0       3650.0    Male\n",
              "6   Adelie  Torgersen            38.9  ...              181.0       3625.0  Female\n",
              "7   Adelie  Torgersen            39.2  ...              195.0       4675.0    Male\n",
              "12  Adelie  Torgersen            41.1  ...              182.0       3200.0  Female\n",
              "13  Adelie  Torgersen            38.6  ...              191.0       3800.0    Male\n",
              "14  Adelie  Torgersen            34.6  ...              198.0       4400.0    Male\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRMV3UDhR7_h"
      },
      "source": [
        "X = pd.get_dummies(dataset.iloc[:,:-1])\n",
        "Y = pd.get_dummies(dataset.iloc[:,-1:])\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nixzt78YVCsQ",
        "outputId": "b7d2261c-7c69-41a5-e7bf-f46ea9809673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(249, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7uy-txkTbJm",
        "outputId": "1c99afa0-dc73-4ed5-98c5-963705a90ceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(249, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNUYu-dfRV6Y"
      },
      "source": [
        "model1 = keras.models.Sequential() \n",
        "layer_11 = keras.layers.Dense(9, activation=\"relu\")  #Numeros 9,8,5,2.. depende de las capas que tengo arriba. tengo 10\n",
        "layer_22 = keras.layers.Dense(7, activation=\"relu\")\n",
        "layer_33 = keras.layers.Dense(5, activation=\"relu\")\n",
        "output1 = keras.layers.Dense(2, activation=\"softmax\") #como a la salida hay 2 - sex male y sex female\n",
        "model1.add(layer_11)\n",
        "model1.add(layer_22)\n",
        "model1.add(layer_33)\n",
        "model1.add(output1)\n",
        "model1.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wobsSQ5qRW5P",
        "outputId": "6a1427e9-b7ab-4051-e3d6-a11895648e0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model1.fit(X_train, Y_train, epochs=300)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 375.6163\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 318.9823\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 270.5446\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 224.7025\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 185.3603\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 150.6699\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 118.0849\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 87.9709\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 61.5005\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 37.1696\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.0180\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8608\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6619\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6546\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6478\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6417\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6355\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6341\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6314\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6235\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6249\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6220\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6261\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6172\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6169\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6220\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6200\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6193\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6152\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6193\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6130\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6177\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6262\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6145\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6220\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6112\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6197\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6191\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6143\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6211\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6213\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6188\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6248\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6257\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6129\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6130\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6336\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6558\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6341\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6659\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6612\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6221\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6310\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6133\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6152\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6180\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6167\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6270\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6200\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6115\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6110\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6173\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6157\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6329\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6116\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6120\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6295\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6115\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6093\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6248\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6455\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6396\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6279\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6154\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6175\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6172\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6105\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6067\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6128\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6073\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6306\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6248\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6441\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6563\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6699\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6389\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6103\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6172\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6156\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6262\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6235\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6066\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6074\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6150\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6184\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6101\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6241\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6130\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6148\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6251\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6217\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6177\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6095\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6229\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6058\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6072\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6078\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6070\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6049\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6180\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6154\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6155\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6417\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6077\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6289\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6055\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6041\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6065\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6069\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6309\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6123\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6095\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6188\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6282\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6187\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6095\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6172\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6585\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6536\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6391\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6586\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6070\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6247\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6264\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6028\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6083\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6241\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6038\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6113\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6319\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6188\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6027\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6121\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6062\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6281\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6204\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6203\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6086\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6081\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6601\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6306\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6115\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6070\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6186\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6429\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6974\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6406\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6477\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6157\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6230\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6188\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6513\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6185\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6126\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6422\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6248\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6903\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7048\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6207\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6140\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6438\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6497\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6578\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6405\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6270\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6020\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6171\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6155\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6217\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6064\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6409\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7010\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7154\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7148\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7132\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7112\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7098\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7082\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7069\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7053\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7042\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7033\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7023\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7016\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7004\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6999\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6992\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6986\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6981\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6977\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6972\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6967\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6965\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6960\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6959\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6955\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6952\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6950\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6949\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6947\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6945\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6943\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6942\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6941\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6939\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6939\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6938\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6937\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6936\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6936\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6935\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6936\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6934\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6933\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6933\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6933\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6932\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6932\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6932\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6932\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6931\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6931\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6931\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6932\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6931\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6931\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6931\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6931\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6930\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6931\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6930\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6930\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6930\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6930\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6929\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6929\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6930\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6929\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3f17b82990>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLCbHARt7xdw"
      },
      "source": [
        "# Eliminar capas de un modelo secuencial.\n",
        "\n",
        "Es posible eliminar capas de un modelo secuencial utilizando el método .pop()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4a4s7_V6dRW"
      },
      "source": [
        "model1.pop() #Eliminamos la output"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCBa4502QvBV"
      },
      "source": [
        "model1.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\") #Y como volvemos a compilar, nose quedamos con el resto"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLykN8GY8SZI",
        "outputId": "54b8111d-499c-4af1-91e0-de5d38463889"
      },
      "source": [
        "model1.predict(X_train).shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(249, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcllTz2Q8UH_",
        "outputId": "6dace76f-5d44-4e00-a84d-d86576369325"
      },
      "source": [
        "len(model1.layers)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn6qEJvlQoi6",
        "outputId": "640a621e-9bfa-4d3f-a5ea-9a0e9887457d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model1.predict(X_train)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.02426542, 0.01519356, 0.        ],\n",
              "       [0.        , 0.        , 0.02426542, 0.01519356, 0.        ],\n",
              "       [0.        , 0.        , 0.02426542, 0.01519356, 0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.02426542, 0.01519356, 0.        ],\n",
              "       [0.        , 0.        , 0.02426542, 0.01519356, 0.        ],\n",
              "       [0.        , 0.        , 0.02426542, 0.01519356, 0.        ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYWuXBU_WKeU",
        "outputId": "1c7be2f3-c668-4fea-b7e3-355936d7130a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model1.layers #como he hecho pop, ha quitado la capa penultima"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.dense.Dense at 0x7f3f17b89bd0>,\n",
              " <keras.layers.core.dense.Dense at 0x7f3f17b89e90>,\n",
              " <keras.layers.core.dense.Dense at 0x7f3f17b89810>]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HgsPWzi9OMr"
      },
      "source": [
        "# API Funcional\n",
        "\n",
        "La api funcional de Keras plantea construir un modelo mediante funciones. Las capas definidas en esta api se estructuran como funciones de Python cuya entrada es la salida de la capa anterior. Para construir un modelo utilizando la API Funcional de Keras hay que seguir los siguientes pasos:\n",
        "\n",
        "- Definir la entrada con keras.layers.Input()\n",
        "- Definir las capas de keras.layers\n",
        "- Definir el modelo con keras.models.Model()\n",
        "- Compilar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZgVO8rk_5Rg"
      },
      "source": [
        "dataset = sns.load_dataset(\"iris\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myGihdhu9NhT"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(4,))\n",
        "layer_1_def = keras.layers.Dense(5, activation=\"relu\")\n",
        "output_def = keras.layers.Dense(3, activation=\"softmax\")\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_z9fZAXYh45"
      },
      "source": [
        "# lo hemos separado, se hace junto pero para ver mejor\n",
        "layer_1 = layer_1_def(input_layer)\n",
        "output = output_def(layer_1)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of4eRXn-YiGk"
      },
      "source": [
        "model = keras.Model(inputs=input_layer, outputs=output)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyqA_4wR8ZD3"
      },
      "source": [
        "X = dataset.iloc[:,:-1]\n",
        "Y = dataset.iloc[:,-1:]\n",
        "Y_dummies = pd.get_dummies(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y_dummies)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUi4MMH2_9hI",
        "outputId": "289ab6be-8381-47cc-fd50-1eb288dfffdf"
      },
      "source": [
        "model.fit(X_train,Y_train, epochs=200)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.0231\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.9729\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.9282\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.8827\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.8389\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.7962\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.7572\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.7184\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.6808\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.6444\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.6098\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5785\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.5456\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.5166\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4888\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4619\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4358\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4136\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3904\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3693\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3497\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3304\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3136\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2968\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2805\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2673\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2532\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2405\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2291\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2174\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2072\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1977\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1886\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1798\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1718\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1650\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1568\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1502\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1443\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1385\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1325\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1278\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1222\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1178\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1132\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1093\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1049\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1013\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0983\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0947\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0917\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0893\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0864\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0838\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0815\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0793\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0769\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0748\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0730\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0710\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0693\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0674\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0658\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0642\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0628\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0612\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0598\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0584\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0570\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0557\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0546\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0534\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0521\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0511\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0499\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0489\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0478\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0468\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0458\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0446\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0438\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0426\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0417\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0407\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0396\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0388\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0379\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0368\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0360\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0350\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0341\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0332\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0322\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0314\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0305\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0294\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0286\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0276\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0267\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0258\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0249\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0238\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0228\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0219\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0209\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0199\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0189\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0180\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0170\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0159\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0149\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0139\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0128\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0117\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0106\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0095\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0084\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0073\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0062\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0050\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0038\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0026\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0015\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0002\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9990\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9977\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9964\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9951\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9938\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9925\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9911\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9897\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9883\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9869\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9855\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9840\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9825\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9810\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9795\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9779\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9764\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9747\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9732\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9715\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9698\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9681\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9665\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9647\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9629\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9611\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9593\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9575\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9556\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9537\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9518\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9498\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9479\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9458\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9438\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9418\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9397\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9376\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9354\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9333\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9311\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9289\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9267\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9243\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9220\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9197\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9174\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9151\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9128\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9104\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9081\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9057\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9033\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9009\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8985\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8961\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8937\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8913\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8888\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8865\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8842\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8819\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8796\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8773\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8751\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8729\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8708\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8687\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8665\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8643\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8622\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.8601\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8581\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8559\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8540\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3f1ec514d0>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8CFBzwKBEYH"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Construid un modelo de 3 capas densas utilizando la API Funcional de Keras sobre el dataset penguins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a12hrOu0BkH3"
      },
      "source": [
        "# Acceder a las capas intermedias de un modelo\n",
        "\n",
        "A veces es interesante poder acceder a la salida de una capa intermedia de un modelo entrenado previamente. Para ello es necesario construir un nuevo modelo definiendo una nueva salida.\n",
        "\n",
        "Una vez definida la nueva salida es posible aplicar análisis dimensional (comprobar las dimensiones de la salida) para comprender más acerca del modelo y si hemos elegido la capa correcta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsdBZGRsZwpt"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMvVKvM4__S5"
      },
      "source": [
        "new_output = model.layers[1]\n",
        "model_2 = keras.Model(inputs=input_layer, outputs=new_output.output)\n",
        "model_2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN75ZkcHZ73O",
        "outputId": "fcea87f4-7f5b-44e4-c863-7aa194d9511f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "plot_model(model)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4bGChv_aIJ0",
        "outputId": "3997a149-3c59-43c0-ddbd-9a91cc37dea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_2.predict(X_test).shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT2m6OXHZN3A",
        "outputId": "70f96b60-3830-4d66-9684-0a131f98da16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Accedo a las capas\n",
        "\n",
        "model.layers[1]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f3f1eb668d0>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZnIcGZpZRyl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfELBMfOCD4A",
        "outputId": "f8c62e05-f386-4dd0-f648-59c1b81e672a"
      },
      "source": [
        "model_2.predict(X_test).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh5-fozOCiNE"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Generad nuevos modelos que tengan como salida las capas intermedias de vuestro modelo funcional anterior. Realizad análisis dimensional sobre las salidas de las capas anteriores y comprobad si son las dimensiones correctas de esa capa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuchreSTChhb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1OSaLDsCf6y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}